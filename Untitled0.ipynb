{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "al5zby3WQfB3",
        "outputId": "2df79208-37fe-42e3-eea8-1333508d392e"
      },
      "outputs": [],
      "source": [
        "%pip install git+https://github.com/modAL-python/modAL.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "kX-uJtXBQwz3",
        "outputId": "15744395-e881-4cdd-da2d-f8f89d8fb769"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import modAL\n",
        "from modAL.models import ActiveLearner\n",
        "from skorch import NeuralNetClassifier\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import KMNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "from modAL.uncertainty import uncertainty_sampling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2nGeHWqY5l3",
        "outputId": "20f8005b-dad6-4a26-a793-422b8d226354"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgabriele-deleonardis\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "%pip install wandb -q\n",
        "import wandb\n",
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "09GHqxVKZGLH",
        "outputId": "dc639639-124c-48f2-ac14-2d630ac8372c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgabriele-deleonardis\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/gabrieledele/Downloads/wandb/run-20231221_200442-i12t345y</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/gabriele-deleonardis/ML4NLP2/runs/i12t345y' target=\"_blank\">run1</a></strong> to <a href='https://wandb.ai/gabriele-deleonardis/ML4NLP2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/gabriele-deleonardis/ML4NLP2' target=\"_blank\">https://wandb.ai/gabriele-deleonardis/ML4NLP2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/gabriele-deleonardis/ML4NLP2/runs/i12t345y' target=\"_blank\">https://wandb.ai/gabriele-deleonardis/ML4NLP2/runs/i12t345y</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/gabriele-deleonardis/ML4NLP2/runs/i12t345y?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x10fc03250>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.init(project=\"ML4NLP2\", name=\"run1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-z-zh7LQNj5",
        "outputId": "28ccabd8-3477-4290-ab90-a2c351801139",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "This example demonstrates how to use the active learning interface with Pytorch.\n",
        "The example uses Skorch, a scikit learn wrapper of Pytorch.\n",
        "For more info, see https://skorch.readthedocs.io/en/stable/\n",
        "\"\"\"\n",
        "'''\n",
        "import numpy as np\n",
        "import torch\n",
        "from modAL.models import ActiveLearner\n",
        "from skorch import NeuralNetClassifier\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import KMNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "'''\n",
        "\n",
        "# build class for the skorch API\n",
        "\n",
        "class VGG11_Dropout(nn.Module):\n",
        "    def __init__(self, num_classes=10, dropout_enabled=True):\n",
        "        super(VGG11_Dropout, self).__init__()\n",
        "        self.dropout_enabled = dropout_enabled\n",
        "\n",
        "        self.convs = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.8) if dropout_enabled else nn.Identity(),  # Added dropout\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.5) if dropout_enabled else nn.Identity(),  # Added dropout\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.5) if dropout_enabled else nn.Identity(),  # Added dropout\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.5) if dropout_enabled else nn.Identity(),  # Added dropout\n",
        "            nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(512 * 1 * 1, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5) if dropout_enabled else nn.Identity(),  # Added dropout\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5) if dropout_enabled else nn.Identity(),  # Added dropout\n",
        "            nn.Linear(4096, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.convs(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "# create the classifier\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "classifier = NeuralNetClassifier(VGG11_Dropout,\n",
        "                                 # max_epochs=100,\n",
        "                                 criterion=nn.CrossEntropyLoss,\n",
        "                                 optimizer=torch.optim.SGD,\n",
        "                                 train_split=None,\n",
        "                                 verbose=1,\n",
        "                                 device=device)\n",
        "\n",
        "\"\"\"\n",
        "Data wrangling\n",
        "1. Reading data from torchvision\n",
        "2. Assembling initial training data for ActiveLearner\n",
        "3. Generating the pool\n",
        "\"\"\"\n",
        "\n",
        "kmnist_data = KMNIST(root='/Users/gabrieledele', download=True, transform=ToTensor())\n",
        "dataloader = DataLoader(kmnist_data, shuffle=True, batch_size=60000)\n",
        "X, y = next(iter(dataloader))\n",
        "\n",
        "# read training data\n",
        "X_train, X_test, y_train, y_test = X[:50000], X[50000:], y[:50000], y[50000:]\n",
        "X_train = X_train.reshape(50000, 1, 28, 28)\n",
        "X_test = X_test.reshape(10000, 1, 28, 28)\n",
        "\n",
        "# assemble initial data\n",
        "n_initial = 1000\n",
        "initial_idx = np.random.choice(range(len(X_train)), size=n_initial, replace=False)\n",
        "X_initial = X_train[initial_idx]\n",
        "y_initial = y_train[initial_idx]\n",
        "\n",
        "# generate the pool\n",
        "# remove the initial data from the training dataset\n",
        "X_pool = np.delete(X_train, initial_idx, axis=0)\n",
        "y_pool = np.delete(y_train, initial_idx, axis=0)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Training the ActiveLearner\n",
        "\"\"\"\n",
        "\n",
        "# initialize ActiveLearner\n",
        "learner = ActiveLearner(\n",
        "    estimator=classifier,\n",
        "    query_strategy=uncertainty_sampling,\n",
        "    X_training=X_initial, y_training=y_initial,\n",
        ")\n",
        "\n",
        "# the active learning loop\n",
        "n_queries = 10\n",
        "for idx in range(n_queries):\n",
        "    query_idx, query_instance = learner.query(X_pool, n_instances=100)\n",
        "    learner.teach(X_pool[query_idx], y_pool[query_idx], only_new=True)\n",
        "    # remove queried instance from pool\n",
        "    X_pool = np.delete(X_pool, query_idx, axis=0)\n",
        "    y_pool = np.delete(y_pool, query_idx, axis=0)\n",
        "\n",
        "# the final accuracy score\n",
        "print(\"Learner/Accuracy score is:\", learner.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0uJAG6wZe-hz",
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wL5e0491e-8i"
      },
      "outputs": [],
      "source": [
        "class VGG11_(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VGG11_, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        # convolutional layers\n",
        "        self.conv_layers = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.8),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.5),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.5),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.5),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.5),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            #nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.5),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.5),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "\n",
        "        # fully connected linear layers\n",
        "        self.linear_layers = nn.Sequential(\n",
        "            nn.Linear(in_features=512*1*1, out_features=4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(in_features=4096, out_features=4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(in_features=4096, out_features=self.num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        # flatten to prepare for the fully connected layers\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear_layers(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-d_Hg-Ofbs_",
        "outputId": "d5543556-6fdc-4b94-9a20-82783d680acf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3031\u001b[0m  9.5973\n",
            "      2        \u001b[36m2.3024\u001b[0m  1.7279\n",
            "      3        \u001b[36m2.3022\u001b[0m  1.9653\n",
            "      4        2.3024  1.6700\n",
            "      5        \u001b[36m2.3020\u001b[0m  1.6374\n",
            "      6        2.3022  1.6041\n",
            "      7        2.3020  1.5535\n",
            "      8        \u001b[36m2.3019\u001b[0m  1.6987\n",
            "      9        \u001b[36m2.3019\u001b[0m  1.7287\n",
            "     10        \u001b[36m2.3017\u001b[0m  1.6709\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3004\u001b[0m  0.8527\n",
            "      2        \u001b[36m2.2881\u001b[0m  0.0990\n",
            "      3        \u001b[36m2.2764\u001b[0m  0.1095\n",
            "      4        \u001b[36m2.2626\u001b[0m  0.1776\n",
            "      5        \u001b[36m2.2523\u001b[0m  0.1626\n",
            "      6        \u001b[36m2.2378\u001b[0m  0.1566\n",
            "      7        \u001b[36m2.2264\u001b[0m  0.1614\n",
            "      8        \u001b[36m2.2154\u001b[0m  0.1587\n",
            "      9        \u001b[36m2.2037\u001b[0m  0.1931\n",
            "     10        \u001b[36m2.1899\u001b[0m  0.1691\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3003\u001b[0m  0.1210\n",
            "      2        \u001b[36m2.2985\u001b[0m  0.0999\n",
            "      3        \u001b[36m2.2982\u001b[0m  0.1586\n",
            "      4        \u001b[36m2.2972\u001b[0m  0.1860\n",
            "      5        \u001b[36m2.2965\u001b[0m  0.1717\n",
            "      6        \u001b[36m2.2948\u001b[0m  0.1668\n",
            "      7        \u001b[36m2.2929\u001b[0m  0.1617\n",
            "      8        2.2930  0.1692\n",
            "      9        \u001b[36m2.2916\u001b[0m  0.1581\n",
            "     10        \u001b[36m2.2903\u001b[0m  0.2328\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3019\u001b[0m  0.1605\n",
            "      2        \u001b[36m2.2980\u001b[0m  0.2647\n",
            "      3        \u001b[36m2.2943\u001b[0m  0.1786\n",
            "      4        \u001b[36m2.2907\u001b[0m  0.3453\n",
            "      5        \u001b[36m2.2873\u001b[0m  0.1585\n",
            "      6        \u001b[36m2.2840\u001b[0m  0.2706\n",
            "      7        \u001b[36m2.2792\u001b[0m  0.5139\n",
            "      8        \u001b[36m2.2740\u001b[0m  0.2612\n",
            "      9        \u001b[36m2.2718\u001b[0m  0.2118\n",
            "     10        \u001b[36m2.2697\u001b[0m  0.1697\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3058\u001b[0m  0.1147\n",
            "      2        \u001b[36m2.3029\u001b[0m  0.2202\n",
            "      3        \u001b[36m2.3014\u001b[0m  0.2029\n",
            "      4        \u001b[36m2.2984\u001b[0m  0.1809\n",
            "      5        \u001b[36m2.2948\u001b[0m  0.1766\n",
            "      6        \u001b[36m2.2927\u001b[0m  0.1572\n",
            "      7        \u001b[36m2.2910\u001b[0m  0.1556\n",
            "      8        \u001b[36m2.2897\u001b[0m  0.1565\n",
            "      9        \u001b[36m2.2853\u001b[0m  0.1562\n",
            "     10        \u001b[36m2.2833\u001b[0m  0.1567\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3013\u001b[0m  0.1479\n",
            "      2        \u001b[36m2.2989\u001b[0m  0.2164\n",
            "      3        \u001b[36m2.2955\u001b[0m  0.1863\n",
            "      4        \u001b[36m2.2939\u001b[0m  0.1565\n",
            "      5        \u001b[36m2.2878\u001b[0m  0.1642\n",
            "      6        \u001b[36m2.2844\u001b[0m  0.2055\n",
            "      7        \u001b[36m2.2818\u001b[0m  0.1868\n",
            "      8        \u001b[36m2.2794\u001b[0m  0.1566\n",
            "      9        \u001b[36m2.2755\u001b[0m  0.1565\n",
            "     10        \u001b[36m2.2738\u001b[0m  0.1691\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3040\u001b[0m  0.1418\n",
            "      2        \u001b[36m2.2966\u001b[0m  0.2260\n",
            "      3        \u001b[36m2.2888\u001b[0m  0.1766\n",
            "      4        \u001b[36m2.2846\u001b[0m  0.1951\n",
            "      5        \u001b[36m2.2782\u001b[0m  0.1945\n",
            "      6        \u001b[36m2.2709\u001b[0m  0.1936\n",
            "      7        \u001b[36m2.2646\u001b[0m  0.1929\n",
            "      8        \u001b[36m2.2584\u001b[0m  0.1602\n",
            "      9        \u001b[36m2.2516\u001b[0m  0.1564\n",
            "     10        \u001b[36m2.2450\u001b[0m  0.1577\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3022\u001b[0m  0.1151\n",
            "      2        \u001b[36m2.2985\u001b[0m  0.1305\n",
            "      3        \u001b[36m2.2937\u001b[0m  0.1885\n",
            "      4        \u001b[36m2.2903\u001b[0m  0.1653\n",
            "      5        \u001b[36m2.2877\u001b[0m  0.1526\n",
            "      6        \u001b[36m2.2834\u001b[0m  0.1720\n",
            "      7        \u001b[36m2.2814\u001b[0m  0.1858\n",
            "      8        \u001b[36m2.2767\u001b[0m  0.1862\n",
            "      9        \u001b[36m2.2733\u001b[0m  0.1919\n",
            "     10        \u001b[36m2.2690\u001b[0m  0.1765\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3005\u001b[0m  0.1233\n",
            "      2        \u001b[36m2.2979\u001b[0m  0.2167\n",
            "      3        \u001b[36m2.2956\u001b[0m  0.1650\n",
            "      4        \u001b[36m2.2948\u001b[0m  0.1810\n",
            "      5        \u001b[36m2.2915\u001b[0m  0.1829\n",
            "      6        \u001b[36m2.2901\u001b[0m  0.2135\n",
            "      7        \u001b[36m2.2892\u001b[0m  0.2016\n",
            "      8        \u001b[36m2.2855\u001b[0m  0.1973\n",
            "      9        \u001b[36m2.2843\u001b[0m  0.1999\n",
            "     10        \u001b[36m2.2815\u001b[0m  0.1831\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3036\u001b[0m  0.1239\n",
            "      2        \u001b[36m2.3007\u001b[0m  0.1246\n",
            "      3        \u001b[36m2.2999\u001b[0m  0.2210\n",
            "      4        \u001b[36m2.2987\u001b[0m  0.2212\n",
            "      5        \u001b[36m2.2962\u001b[0m  0.1584\n",
            "      6        \u001b[36m2.2956\u001b[0m  0.1502\n",
            "      7        \u001b[36m2.2943\u001b[0m  0.1450\n",
            "      8        2.2948  0.1464\n",
            "      9        2.2948  0.1579\n",
            "     10        \u001b[36m2.2913\u001b[0m  0.1795\n",
            "Re-initializing module.\n",
            "Re-initializing optimizer.\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.3106\u001b[0m  0.1128\n",
            "      2        \u001b[36m2.3053\u001b[0m  0.2317\n",
            "      3        \u001b[36m2.2986\u001b[0m  0.1912\n",
            "      4        \u001b[36m2.2957\u001b[0m  0.1831\n",
            "      5        \u001b[36m2.2900\u001b[0m  0.1612\n",
            "      6        \u001b[36m2.2846\u001b[0m  0.1595\n",
            "      7        \u001b[36m2.2783\u001b[0m  0.1543\n",
            "      8        \u001b[36m2.2730\u001b[0m  0.1577\n",
            "      9        \u001b[36m2.2686\u001b[0m  0.1575\n",
            "     10        \u001b[36m2.2635\u001b[0m  0.1555\n",
            "Learner/Accuracy score is: 0.0958\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "This example demonstrates how to use the active learning interface with Pytorch.\n",
        "The example uses Skorch, a scikit learn wrapper of Pytorch.\n",
        "For more info, see https://skorch.readthedocs.io/en/stable/\n",
        "\"\"\"\n",
        "'''\n",
        "import numpy as np\n",
        "import torch\n",
        "from modAL.models import ActiveLearner\n",
        "from skorch import NeuralNetClassifier\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import KMNIST\n",
        "from torchvision.transforms import ToTensor\n",
        "'''\n",
        "\n",
        "# build class for the skorch API\n",
        "\n",
        "\"\"\"class VGG11_Dropout(nn.Module):\n",
        "    def __init__(self, num_classes=10, dropout_enabled=True):\n",
        "        super(VGG11_Dropout, self).__init__()\n",
        "        self.dropout_enabled = dropout_enabled\n",
        "\n",
        "        self.convs = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.8) if dropout_enabled else nn.Identity(),  # Added dropout\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.5) if dropout_enabled else nn.Identity(),  # Added dropout\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.5) if dropout_enabled else nn.Identity(),  # Added dropout\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout2d(0.5) if dropout_enabled else nn.Identity(),  # Added dropout\n",
        "            nn.MaxPool2d(2, 2),\n",
        "        )\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(512 * 1 * 1, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5) if dropout_enabled else nn.Identity(),  # Added dropout\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5) if dropout_enabled else nn.Identity(),  # Added dropout\n",
        "            nn.Linear(4096, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.convs(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\"\"\"\n",
        "\n",
        "# create the classifier\n",
        "#device = \"cuda\" #if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "device = torch.device(\"mps\")\n",
        "## mps and not cuda cause of Apple's M1 Processor\n",
        "classifier = NeuralNetClassifier(VGG11_,\n",
        "                                 # max_epochs=100,\n",
        "                                 criterion=nn.CrossEntropyLoss,\n",
        "                                 optimizer=torch.optim.SGD,\n",
        "                                 train_split=None,\n",
        "                                 verbose=1,\n",
        "                                 device=device)\n",
        "\n",
        "\"\"\"\n",
        "Data wrangling\n",
        "1. Reading data from torchvision\n",
        "2. Assembling initial training data for ActiveLearner\n",
        "3. Generating the pool\n",
        "\"\"\"\n",
        "\n",
        "kmnist_data = KMNIST(root='/Users/gabrieledele', download=True, transform=ToTensor())\n",
        "dataloader = DataLoader(kmnist_data, shuffle=True, batch_size=60000)\n",
        "X, y = next(iter(dataloader))\n",
        "\n",
        "# read training data\n",
        "X_train, X_test, y_train, y_test = X[:50000], X[50000:], y[:50000], y[50000:]\n",
        "X_train = X_train.reshape(50000, 1, 28, 28)\n",
        "X_test = X_test.reshape(10000, 1, 28, 28)\n",
        "\n",
        "# assemble initial data\n",
        "n_initial = 1000\n",
        "initial_idx = np.random.choice(range(len(X_train)), size=n_initial, replace=False)\n",
        "X_initial = X_train[initial_idx]\n",
        "y_initial = y_train[initial_idx]\n",
        "\n",
        "# generate the pool\n",
        "# remove the initial data from the training dataset\n",
        "X_pool = np.delete(X_train, initial_idx, axis=0)\n",
        "y_pool = np.delete(y_train, initial_idx, axis=0)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Training the ActiveLearner\n",
        "\"\"\"\n",
        "\n",
        "# initialize ActiveLearner\n",
        "learner = ActiveLearner(estimator=classifier, query_strategy=uncertainty_sampling, X_training=X_initial, y_training=y_initial,)\n",
        "\n",
        "# the active learning loop\n",
        "n_queries = 10\n",
        "for idx in range(n_queries):\n",
        "    query_idx, query_instance = learner.query(X_pool, n_instances=100)\n",
        "    learner.teach(X_pool[query_idx], y_pool[query_idx], only_new=True)\n",
        "    # remove queried instance from pool\n",
        "    X_pool = np.delete(X_pool, query_idx, axis=0)\n",
        "    y_pool = np.delete(y_pool, query_idx, axis=0)\n",
        "\n",
        "# the final accuracy score\n",
        "print(\"Learner/Accuracy score is:\", learner.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "hpW53yLIpfGu",
        "outputId": "d57fbd53-ed8d-4ed6-ab3b-be9cc0650a8f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean accuracy score: 0.10129166666666667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: Network error (ConnectionError), entering retry loop.\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_pred = learner.predict(X_pool)\n",
        "\n",
        "# Calculate mean accuracy score\n",
        "accuracy = accuracy_score(y_pool, y_pred)\n",
        "print(f\"Mean accuracy score: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.], device='mps:0')\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "if torch.backends.mps.is_available():\n",
        "    mps_device = torch.device(\"mps\")\n",
        "    x = torch.ones(1, device=mps_device)\n",
        "    print (x)\n",
        "else:\n",
        "    print (\"MPS device not found.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
